{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP9FyOGaBY8mA8DhhA6PwvY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hhnafis/PIAIC_LangChain_RAG_Project/blob/main/PIAIC_LangChain_RAG_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1gmsikSJIos4",
        "outputId": "47694655-9e69-4e7a-e8f0-579a2cb051a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m427.3/427.3 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.3/50.3 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "pip install -Uq langchain-pinecone langchain-google-genai"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Setup Environment Variables"
      ],
      "metadata": {
        "id": "MzWpcTFde-Dh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pinecone import Pinecone, ServerlessSpec\n",
        "from google.colab import  userdata\n",
        "pinecone_api_key = userdata.get(\"PINECONE_API_KEY\")\n",
        "pc = Pinecone(api_key=pinecone_api_key)"
      ],
      "metadata": {
        "id": "o99o9XBTfHsg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Initializing pinecone(creating index)"
      ],
      "metadata": {
        "id": "SHIgekaDfz2d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "index_name = \"langchain-rag-project\"\n",
        "\n",
        "pc.create_index(\n",
        "    name=index_name,\n",
        "    dimension=768,\n",
        "    metric=\"cosine\",\n",
        "    spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\"),\n",
        ")\n",
        "\n",
        "index = pc.Index(index_name)"
      ],
      "metadata": {
        "id": "qrXkY46_f7vN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Use langchain for RAG Workflow\n",
        "###Use Google Gemini embeddings to vectorize a document"
      ],
      "metadata": {
        "id": "q3fSgO1cgUcs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "import os\n",
        "os.environ['GOOGLE_API_KEY'] = userdata.get(\"GOOGLE_API_KEY\")\n",
        "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")"
      ],
      "metadata": {
        "id": "juvpIFHTgo0T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Setup the document loader"
      ],
      "metadata": {
        "id": "KXZ31la0g5wg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Installing the necessary packages\n",
        "!pip install -Uq langchain-community\n",
        "!pip install -Uq pypdf\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "# # Setup the document loader\n",
        "# file_path = '/content/AI.pdf'\n",
        "# loader = PyPDFLoader(file_path) #Change file path if needed\n",
        "# documents = loader.load()\n",
        "\n",
        "# # Setup the splitter\n",
        "# text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=50)\n",
        "# docs = text_splitter.split_documents(documents)\n",
        "\n",
        "\n",
        "#---------------------------Adding more than one documents--------------------#\n",
        "file_paths = [\"/content/AI.pdf\", \"/content/AI_applications.pdf\", \"/content/AI_and_its_scope_in_academia.pdf\"]\n",
        "all_docs = []\n",
        "\n",
        "for file_path in file_paths:\n",
        "    loader = PyPDFLoader(file_path)\n",
        "    documents = loader.load()\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=50)\n",
        "    docs = text_splitter.split_documents(documents)\n",
        "\n",
        "    for doc in docs:\n",
        "        doc.metadata[\"source\"] = file_path  # Store the file path in metadata\n",
        "\n",
        "    all_docs.extend(docs)\n",
        "\n",
        "docs = all_docs\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "IK-qvO32g9Mn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Embed and store documents in pinecone"
      ],
      "metadata": {
        "id": "-ztuPDD2j_oT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_pinecone import PineconeVectorStore\n",
        "vector_store = PineconeVectorStore(index=index,embedding=embeddings)\n",
        "\n",
        "from uuid import uuid4\n",
        "from langchain_core.documents import Document\n",
        "\n",
        "# Iterating through the split documents and creating individual Document objects\n",
        "for i, doc in enumerate(docs):\n",
        "    document = Document(page_content=doc.page_content, metadata={\"source\": doc.metadata[\"source\"]})\n",
        "    uuid = str(uuid4())  # Generated a unique ID for each document\n",
        "    vector_store.add_documents(documents=[document], ids=[uuid]) # Added document to Pinecone"
      ],
      "metadata": {
        "id": "72hIkO3bkL1R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Set Up Retriever"
      ],
      "metadata": {
        "id": "zp8hDimokglk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import textwrap\n",
        "results = vector_store.similarity_search(\n",
        "    \"What is  AI? and what is the role of AI in academia?\",\n",
        "    k=3,\n",
        "    # filter={\"source\": doc.metadata[\"source\"]},\n",
        ")\n",
        "for res in results:\n",
        "    wrapped_content = textwrap.fill(res.page_content,width=150)\n",
        "\n",
        "    print(\"-\" * 30)\n",
        "    print(wrapped_content)\n",
        "    print(\"\\n\")\n",
        "    print(res.metadata)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZL83w-_kiTh",
        "outputId": "0b57b8af-3a3b-4b75-d2eb-f8b3bbe67806"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------\n",
            "working to develop systems that can help students to choose  majors based on areas where they succeed and struggle. While  students don’t have to take\n",
            "the advice, it could mark a  brave  new world of college major selection for future students.    3.1.6. It is altering how we find and interact with\n",
            "information  We rarely even notice the AI systems that affect the  information we see and find on a daily basis. Google adapts  results to u sers\n",
            "based on location, Amazon makes  recommendations based on previous purchases, Siri adapts to  your needs and commands, and nearly all web ads are\n",
            "geared  toward your interests and shopping preferences.   These kinds of intelligent systems play a big role in how we  interact with information in\n",
            "our personal and professional  lives, and could just change how we find and use information  in schools and academia as well. Over the past few\n",
            "decades,  AI-based systems have already radically changed how we\n",
            "\n",
            "\n",
            "{'source': '/content/AI_and_its_scope_in_academia.pdf'}\n",
            "------------------------------\n",
            "working to develop systems that can help students to choose  majors based on areas where they succeed and struggle. While  students don’t have to take\n",
            "the advice, it could mark a  brave  new world of college major selection for future students.    3.1.6. It is altering how we find and interact with\n",
            "information  We rarely even notice the AI systems that affect the  information we see and find on a daily basis. Google adapts  results to u sers\n",
            "based on location, Amazon makes  recommendations based on previous purchases, Siri adapts to  your needs and commands, and nearly all web ads are\n",
            "geared  toward your interests and shopping preferences.   These kinds of intelligent systems play a big role in how we  interact with information in\n",
            "our personal and professional  lives, and could just change how we find and use information  in schools and academia as well. Over the past few\n",
            "decades,  AI-based systems have already radically changed how we\n",
            "\n",
            "\n",
            "{'source': 'AI.pdf'}\n",
            "------------------------------\n",
            "specifically to how AI is defined in contemporary IS research.    References:    1.\n",
            "http://en.wikibooks.org/wiki/Computer_Science:Artificial_Intelligence http://www.howstuffworks.com/  arificialintelligence  2. http://\n",
            "www.google.co.in   3. http://www.library.thinkquest.org   4. https://www.javatpoint.com/application-of-ai  5. https://www.educba.com/artificial-\n",
            "intelligence-techniques/   6. https://www.cigionline.orgw/articles/cybersecuritybattlefield/?utm_source=google_ads&utm_medium=\n",
            "grant&gclid=EAIaIQobChMIsdz9qLSF_AIVzQ0rCh1bNQylEAA YAiAAEgI40_D_BwE\n",
            "\n",
            "\n",
            "{'source': '/content/AI_applications.pdf'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Setup the Google Gemini Flash model"
      ],
      "metadata": {
        "id": "QXvPsoSQpQL1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-1.5-flash\",\n",
        "    temperature=0.2,\n",
        "    max_tokens=None,\n",
        "    timeout=None,\n",
        "    max_retries=2,\n",
        "    verbose=True,\n",
        ")"
      ],
      "metadata": {
        "id": "gSjNPw2Wpcy9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Now combining both the retriever and LLM to make a complete RAG System"
      ],
      "metadata": {
        "id": "2wlNtkS9pm5t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def answer_to_user(query: str):\n",
        "    # Vector Search\n",
        "    vector_results = vector_store.similarity_search(query, k=1)\n",
        "\n",
        "\n",
        "    # Pass the model vector search + user query\n",
        "    final_answer = llm.invoke(\n",
        "        f\"ANSWER THIS USER QUERY: {query}, Here are some references {vector_results}\"\n",
        "    )\n",
        "\n",
        "\n",
        "    return final_answer"
      ],
      "metadata": {
        "id": "M9Xb0ko9psgU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Testing the RAG system"
      ],
      "metadata": {
        "id": "aflTGtNFqDtP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "answer = answer_to_user(\"What is Artificial Intelligence?\")\n",
        "answer.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "RtGCuGyJqMcs",
        "outputId": "9e030151-9bb4-41a5-e991-6913f17e8884"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Based on the provided text, Artificial Intelligence (AI) is a field that uses advanced techniques to solve real-life problems.  It encompasses subfields like Machine Learning (ML) and Deep Learning (DL), with ML being a subset of AI and DL being a subset of ML.  One example of an AI application mentioned is Natural Language Processing (NLP), which focuses on computer-human communication (like Google Translate).'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note: By comparing the output of this RAG system with that of a simple retriever, we can observe the efficiency with which the RAG system produces the output."
      ],
      "metadata": {
        "id": "uBU1_2pFrBuC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Deployment of the RAG system as an API"
      ],
      "metadata": {
        "id": "fmSbT2tXuWk4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Complete RAG system deployment using FastAPI\n",
        "!pip install -Uq fastapi uvicorn\n",
        "#importing necessary libraries\n",
        "from fastapi import FastAPI, HTTPException\n",
        "from pydantic import BaseModel\n",
        "\n",
        "from langchain_core.documents import Document\n",
        "\n",
        "# Initialize FastAPI app\n",
        "app = FastAPI(title=\"RAG API\", description=\"Retrieval Augmented Generation API\")\n",
        "\n",
        "def answer_to_user(query: str):\n",
        "    vector_results = vector_store.similarity_search(query, k=1)\n",
        "\n",
        "    context_content = vector_results[0].page_content if vector_results else \"\"\n",
        "    prompt = f\"\"\"\n",
        "    Question:\n",
        "    {query}\n",
        "\n",
        "    Context:\n",
        "    {context_content}\n",
        "\n",
        "\n",
        "    Response (Generated by Gemini):\n",
        "\n",
        "    \"\"\"\n",
        "    final_answer = llm.invoke(prompt)\n",
        "\n",
        "    return {\"question\":query, \"answer\":final_answer.content}\n",
        "\n",
        "\n",
        "class Query(BaseModel):\n",
        "    query: str\n",
        "#API end point\n",
        "@app.post(\"/query\")\n",
        "async def query_rag(query_data: Query):\n",
        "    try:\n",
        "        answer = answer_to_user(query_data.query)\n",
        "        response = {\n",
        "            \"Question\": query_data.query,\n",
        "            \"Response (Generated by Gemini)\": answer.content,\n",
        "        }\n",
        "        return response\n",
        "    except Exception as e:\n",
        "        raise HTTPException(status_code=500, detail=f\"Error processing query: {str(e)}\")"
      ],
      "metadata": {
        "id": "YKP_nwcxg7uS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_query = \"What were the major milestones in AI development during the 20th century?\"\n",
        "test_answer = answer_to_user(test_query)\n",
        "\n",
        "# Print the question and answer in the desired format\n",
        "print(f\"Question:\\n{test_answer['question']}\\n\\nResponse (Generated by Gemini):\\n\\\"{test_answer['answer']}\\\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1hyAB1A3u5t8",
        "outputId": "0ed0b9aa-5050-4530-fe36-c219d8937752"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question:\n",
            "What were the major milestones in AI development during the 20th century?\n",
            "\n",
            "Response (Generated by Gemini):\n",
            "\"The provided context mentions a resurgence of AI in the 2010s but lacks detail on 20th-century milestones.  To answer the question, we need to look beyond the given text.  Here are some major milestones in AI development during the 20th century:\n",
            "\n",
            "* **1950s:**\n",
            "    * **Alan Turing's \"Computing Machinery and Intelligence\" (1950):**  This paper proposed the Turing Test, a benchmark for machine intelligence.\n",
            "    * **Dartmouth Workshop (1956):**  Widely considered the birth of AI as a field.  Researchers coined the term \"artificial intelligence\" and laid out the ambitious goals of the field.  Early programs like the Logic Theorist and the General Problem Solver were developed.\n",
            "\n",
            "* **1960s:**\n",
            "    * **Development of early expert systems:** Programs designed to mimic the decision-making of human experts in specific domains (e.g., medical diagnosis).\n",
            "    * **ELIZA (1966):** A natural language processing program that simulated a Rogerian psychotherapist, demonstrating the potential of AI in human-computer interaction.\n",
            "\n",
            "* **1970s:**\n",
            "    * **First AI winter:** Funding for AI research decreased due to unmet expectations and limitations in computing power.\n",
            "\n",
            "* **1980s:**\n",
            "    * **Expert systems boom:**  Expert systems found practical applications in various industries, leading to renewed interest in AI.\n",
            "    * **Connectionism gains traction:** Research into artificial neural networks experienced a resurgence.\n",
            "\n",
            "* **1990s:**\n",
            "    * **Second AI winter:**  Further disillusionment with expert systems and limitations in computing power led to another period of reduced funding.\n",
            "    * **Advances in machine learning:**  Algorithms like support vector machines and decision trees began to show promise.\n",
            "    * **Deep Blue defeats Garry Kasparov (1997):**  IBM's chess-playing computer marked a significant milestone in game playing AI.\n",
            "\n",
            "\n",
            "This list highlights key events and trends.  The 20th century saw periods of great optimism followed by setbacks, reflecting the inherent challenges in creating truly intelligent machines.  The context provided focuses on the recent resurgence, but the foundation for that resurgence was laid throughout the previous century.\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Ended!!!!!"
      ],
      "metadata": {
        "id": "B0saGPK--vL6"
      }
    }
  ]
}